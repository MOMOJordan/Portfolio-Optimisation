{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-15T21:25:02.441897Z",
     "start_time": "2025-09-15T21:25:02.392996Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "data = pd.read_csv(fr\"/Users/jordan/Documents/BarclaysStage/portfolio_analysis/positions.csv\",index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-15T21:25:02.449582Z",
     "start_time": "2025-09-15T21:25:02.402065Z"
    }
   },
   "id": "84fcff7afba4897d"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "                 name ticker country currency                  sector  \\\nstock_id                                                                \n1            equity_1    AGI     DEU      EUR  Information Technology   \n2            equity_2    PWH     RUS      USD        Consumer Staples   \n3            equity_3    NDE     DEU      USD             Industrials   \n4            equity_4    ABB     USA      USD              Financials   \n5            equity_5    WRF     RUS      USD               Utilities   \n...               ...    ...     ...      ...                     ...   \n2996      equity_2996    HSH     CAN      CAD  Information Technology   \n2997      equity_2997    QLG     BEL      EUR               Utilities   \n2998      equity_2998    YOV     DEU      USD               Utilities   \n2999      equity_2999    YFG     HKG      CNY  Consumer Discretionary   \n3000      equity_3000    TEG     USA      CAD             Industrials   \n\n                                 industry  \\\nstock_id                                    \n1                     Software & Services   \n2                 Food Beverage & Tobacco   \n3                           Capital Goods   \n4                               Insurance   \n5                               Utilities   \n...                                   ...   \n2996      Technology Hardware & Equipment   \n2997                            Utilities   \n2998                            Utilities   \n2999                            Retailing   \n3000       Commercial Services & Supplies   \n\n                                  sub_industry      beta  avg_daily_volume  \\\nstock_id                                                                     \n1                             Systems Software  1.735624             10043   \n2                          Meat Poultry & Fish  0.675354            640830   \n3                   Heavy Electrical Equipment  0.699394             36094   \n4                                  Reinsurance  2.215079         135786553   \n5                           Electric Utilities  1.259133             26094   \n...                                        ...       ...               ...   \n2996         Electronic Manufacturing Services  1.723244              3193   \n2997                             Gas Utilities  0.977303         291651784   \n2998                             Gas Utilities  1.186587              1955   \n2999                           Internet Retail  0.799109          11685566   \n3000      Human Resource & Employment Services  1.879576            139458   \n\n           side  posn_shares  cost_basis_local  market_price_local  \nstock_id                                                            \n1         SHORT        -4810            145.19              147.06  \n2          LONG        38342            112.48              100.28  \n3         SHORT       -19881             43.36               41.56  \n4         SHORT      -100194             24.79               26.38  \n5          LONG         3963            149.90              149.53  \n...         ...          ...               ...                 ...  \n2996      SHORT         -232            238.13              249.60  \n2997       LONG        77866             11.07               10.13  \n2998       LONG         3743            141.71              160.19  \n2999       LONG        49551            225.50              235.19  \n3000       LONG         2413            172.00              194.58  \n\n[3000 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>ticker</th>\n      <th>country</th>\n      <th>currency</th>\n      <th>sector</th>\n      <th>industry</th>\n      <th>sub_industry</th>\n      <th>beta</th>\n      <th>avg_daily_volume</th>\n      <th>side</th>\n      <th>posn_shares</th>\n      <th>cost_basis_local</th>\n      <th>market_price_local</th>\n    </tr>\n    <tr>\n      <th>stock_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>equity_1</td>\n      <td>AGI</td>\n      <td>DEU</td>\n      <td>EUR</td>\n      <td>Information Technology</td>\n      <td>Software &amp; Services</td>\n      <td>Systems Software</td>\n      <td>1.735624</td>\n      <td>10043</td>\n      <td>SHORT</td>\n      <td>-4810</td>\n      <td>145.19</td>\n      <td>147.06</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>equity_2</td>\n      <td>PWH</td>\n      <td>RUS</td>\n      <td>USD</td>\n      <td>Consumer Staples</td>\n      <td>Food Beverage &amp; Tobacco</td>\n      <td>Meat Poultry &amp; Fish</td>\n      <td>0.675354</td>\n      <td>640830</td>\n      <td>LONG</td>\n      <td>38342</td>\n      <td>112.48</td>\n      <td>100.28</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>equity_3</td>\n      <td>NDE</td>\n      <td>DEU</td>\n      <td>USD</td>\n      <td>Industrials</td>\n      <td>Capital Goods</td>\n      <td>Heavy Electrical Equipment</td>\n      <td>0.699394</td>\n      <td>36094</td>\n      <td>SHORT</td>\n      <td>-19881</td>\n      <td>43.36</td>\n      <td>41.56</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>equity_4</td>\n      <td>ABB</td>\n      <td>USA</td>\n      <td>USD</td>\n      <td>Financials</td>\n      <td>Insurance</td>\n      <td>Reinsurance</td>\n      <td>2.215079</td>\n      <td>135786553</td>\n      <td>SHORT</td>\n      <td>-100194</td>\n      <td>24.79</td>\n      <td>26.38</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>equity_5</td>\n      <td>WRF</td>\n      <td>RUS</td>\n      <td>USD</td>\n      <td>Utilities</td>\n      <td>Utilities</td>\n      <td>Electric Utilities</td>\n      <td>1.259133</td>\n      <td>26094</td>\n      <td>LONG</td>\n      <td>3963</td>\n      <td>149.90</td>\n      <td>149.53</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2996</th>\n      <td>equity_2996</td>\n      <td>HSH</td>\n      <td>CAN</td>\n      <td>CAD</td>\n      <td>Information Technology</td>\n      <td>Technology Hardware &amp; Equipment</td>\n      <td>Electronic Manufacturing Services</td>\n      <td>1.723244</td>\n      <td>3193</td>\n      <td>SHORT</td>\n      <td>-232</td>\n      <td>238.13</td>\n      <td>249.60</td>\n    </tr>\n    <tr>\n      <th>2997</th>\n      <td>equity_2997</td>\n      <td>QLG</td>\n      <td>BEL</td>\n      <td>EUR</td>\n      <td>Utilities</td>\n      <td>Utilities</td>\n      <td>Gas Utilities</td>\n      <td>0.977303</td>\n      <td>291651784</td>\n      <td>LONG</td>\n      <td>77866</td>\n      <td>11.07</td>\n      <td>10.13</td>\n    </tr>\n    <tr>\n      <th>2998</th>\n      <td>equity_2998</td>\n      <td>YOV</td>\n      <td>DEU</td>\n      <td>USD</td>\n      <td>Utilities</td>\n      <td>Utilities</td>\n      <td>Gas Utilities</td>\n      <td>1.186587</td>\n      <td>1955</td>\n      <td>LONG</td>\n      <td>3743</td>\n      <td>141.71</td>\n      <td>160.19</td>\n    </tr>\n    <tr>\n      <th>2999</th>\n      <td>equity_2999</td>\n      <td>YFG</td>\n      <td>HKG</td>\n      <td>CNY</td>\n      <td>Consumer Discretionary</td>\n      <td>Retailing</td>\n      <td>Internet Retail</td>\n      <td>0.799109</td>\n      <td>11685566</td>\n      <td>LONG</td>\n      <td>49551</td>\n      <td>225.50</td>\n      <td>235.19</td>\n    </tr>\n    <tr>\n      <th>3000</th>\n      <td>equity_3000</td>\n      <td>TEG</td>\n      <td>USA</td>\n      <td>CAD</td>\n      <td>Industrials</td>\n      <td>Commercial Services &amp; Supplies</td>\n      <td>Human Resource &amp; Employment Services</td>\n      <td>1.879576</td>\n      <td>139458</td>\n      <td>LONG</td>\n      <td>2413</td>\n      <td>172.00</td>\n      <td>194.58</td>\n    </tr>\n  </tbody>\n</table>\n<p>3000 rows Ã— 13 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-15T21:25:02.500656Z",
     "start_time": "2025-09-15T21:25:02.456916Z"
    }
   },
   "id": "fda44e7c761b117f"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# ---------- Config ----------\n",
    "BASE_CCY = \"USD\"\n",
    "FX = {  # fill with real rates if given; else keep 1.0 and label in the report\n",
    "    # \"EUR\": 1.08, \"GBP\": 1.30, \"JPY\": 0.0063, ...\n",
    "}\n",
    "THR = dict(beta_drift=0.015, ccy=0.03, bucket=0.05, single_name=0.03, pctadv=0.10)\n",
    "\n",
    "# ---------- Load ----------\n",
    "src = Path(\"positions.csv\")              # your file path\n",
    "out_txt = Path(\"report.txt\")\n",
    "out_xlsx = Path(\"report_tables.xlsx\")\n",
    "\n",
    "df = pd.read_csv(src)\n",
    "df.columns = (df.columns.str.strip().str.lower().str.replace(r\"[\\s\\-]+\",\"_\", regex=True))\n",
    "\n",
    "# ---------- Derived fields ----------\n",
    "df[\"shares\"] = pd.to_numeric(df[\"posn_shares\"], errors=\"coerce\")\n",
    "df[\"price\"]  = pd.to_numeric(df[\"market_price_local\"], errors=\"coerce\")\n",
    "df[\"cost\"]   = pd.to_numeric(df[\"cost_basis_local\"], errors=\"coerce\")\n",
    "df[\"beta\"]   = pd.to_numeric(df[\"beta\"], errors=\"coerce\")\n",
    "df[\"adv\"]    = pd.to_numeric(df[\"avg_daily_volume\"], errors=\"coerce\")\n",
    "\n",
    "# FX to base (fallback = 1.0)\n",
    "df[\"fx_to_base\"] = df[\"currency\"].map(FX).fillna(1.0)\n",
    "\n",
    "# Notional & MV (base)\n",
    "df[\"mv_base\"] = df[\"shares\"] * df[\"price\"] * df[\"fx_to_base\"]\n",
    "df[\"beta_dollars\"] = df[\"beta\"] * df[\"mv_base\"]\n",
    "\n",
    "# Liquidity & PnL\n",
    "df[\"pct_adv\"] = np.where(df[\"adv\"]>0, np.abs(df[\"shares\"])/df[\"adv\"], np.nan)\n",
    "df[\"unrl_pnl\"] = (df[\"price\"] - df[\"cost\"]) * df[\"shares\"]\n",
    "df[\"unrl_pnl_pct\"] = np.where(df[\"cost\"]!=0, df[\"price\"]/df[\"cost\"] - 1.0, np.nan)\n",
    "\n",
    "# ---------- KPIs ----------\n",
    "gross = df[\"mv_base\"].abs().sum()\n",
    "net   = df[\"mv_base\"].sum()\n",
    "long_gross  = df.loc[df[\"mv_base\"]>0, \"mv_base\"].sum()\n",
    "short_gross = df.loc[df[\"mv_base\"]<0, \"mv_base\"].abs().sum()\n",
    "long_pct  = long_gross/(gross or 1.0)\n",
    "short_pct = short_gross/(gross or 1.0)\n",
    "net_beta  = df[\"beta_dollars\"].sum()\n",
    "beta_drift = abs(net_beta)/(gross or 1.0)\n",
    "\n",
    "def gsum(by):\n",
    "    g = df.groupby(by, dropna=False).agg(\n",
    "        net=(\"mv_base\",\"sum\"),\n",
    "        gross=(\"mv_base\", lambda s: s.abs().sum()),\n",
    "        beta_dollars=(\"beta_dollars\",\"sum\"),\n",
    "        names=(\"ticker\",\"nunique\")\n",
    "    ).reset_index()\n",
    "    g[\"pct_gross\"] = g[\"gross\"]/(gross or 1.0)\n",
    "    return g.sort_values(\"pct_gross\", ascending=False)\n",
    "\n",
    "g_ccy  = gsum(\"currency\")\n",
    "g_ctry = gsum(\"country\")\n",
    "g_sect = gsum(\"sector\")\n",
    "\n",
    "# ---------- Flags ----------\n",
    "flags = []\n",
    "if beta_drift > THR[\"beta_drift\"]:\n",
    "    flags.append(f\"Market beta drift {beta_drift:.2%} > {THR['beta_drift']:.2%}\")\n",
    "\n",
    "for label, g, thr in [(\"Currency\", g_ccy, THR[\"ccy\"]),\n",
    "                      (\"Country\",  g_ctry, THR[\"bucket\"]),\n",
    "                      (\"Sector\",   g_sect, THR[\"bucket\"])]:\n",
    "    skew = g.loc[g[\"net\"].abs() > thr * (gross or 1.0)]\n",
    "    for _, r in skew.iterrows():\n",
    "        flags.append(f\"{label} skew {r[label.lower()]}: net {r['net']:.0f} ({r['net']/(gross or 1.0):.2%} of gross)\")\n",
    "\n",
    "big = df.assign(w=lambda x: x[\"mv_base\"].abs()/(gross or 1.0)).query(\"w > @THR['single_name']\")\n",
    "for _, r in big.iterrows():\n",
    "    flags.append(f\"Single-name concentration {r['ticker']}: {r['w']:.2%} of gross\")\n",
    "\n",
    "liq = df.query(\"pct_adv > @THR['pctadv']\")\n",
    "for _, r in liq.iterrows():\n",
    "    flags.append(f\"Liquidity: {r['ticker']} at {r['pct_adv']:.1%} of ADV\")\n",
    "\n",
    "# ---------- Write plaintext ----------\n",
    "def money(x): \n",
    "    try: return f\"{x:,.0f}\"\n",
    "    except: return str(x)\n",
    "\n",
    "lines = []\n",
    "fx_note = \"real FX applied\" if any(v!=1.0 for v in df[\"fx_to_base\"].unique()) else \"FX=1.0 placeholder (exposures approximate)\"\n",
    "lines.append(f\"FACTOR-NEUTRAL EQUITIES REPORT | {datetime.now():%Y-%m-%d %H:%M} | Base: {BASE_CCY} ({fx_note})\")\n",
    "lines.append(f\"Rows: {len(df)}\")\n",
    "lines.append(\"\")\n",
    "lines.append(\"Portfolio KPIs\")\n",
    "lines.append(f\"  Gross: {money(gross)} | Net: {money(net)} | Long%: {long_pct:.1%} | Short%: {short_pct:.1%}\")\n",
    "lines.append(f\"  Net beta-$: {money(net_beta)} | Beta drift: {beta_drift:.2%} of gross\")\n",
    "lines.append(f\"  Liquidity (>%ADV 10%): {(df.loc[df['pct_adv']>0.10,'mv_base'].abs().sum()/(gross or 1.0)):.1%} | \"\n",
    "             f\"Top-10 names: {df['mv_base'].abs().nlargest(10).sum()/(gross or 1.0):.1%}\")\n",
    "lines.append(\"\")\n",
    "for title, g in [(\"Top Currency Buckets\", g_ccy.head(10)),\n",
    "                 (\"Top Country Buckets\",  g_ctry.head(10)),\n",
    "                 (\"Top Sector Buckets\",   g_sect.head(10))]:\n",
    "    t = g.copy()\n",
    "    t[\"net\"] = t[\"net\"].map(money); t[\"gross\"] = t[\"gross\"].map(money)\n",
    "    t[\"beta_dollars\"] = t[\"beta_dollars\"].map(money)\n",
    "    t[\"pct_gross\"] = (t[\"pct_gross\"]*100).map(lambda v: f\"{v:.1f}%\")\n",
    "    lines.append(title)\n",
    "    lines.append(t.to_string(index=False))\n",
    "    lines.append(\"\")\n",
    "\n",
    "lines.append(\"Watchlist Flags\")\n",
    "lines += [f\"  - {f}\" for f in flags] or [\"  (None)\"]\n",
    "out_txt.write_text(\"\\n\".join(lines))\n",
    "\n",
    "# ---------- Workbook ----------\n",
    "with pd.ExcelWriter(out_xlsx, engine=\"xlsxwriter\") as xw:\n",
    "    g_ccy.to_excel(xw, \"by_currency\", index=False)\n",
    "    g_ctry.to_excel(xw, \"by_country\", index=False)\n",
    "    g_sect.to_excel(xw, \"by_sector\", index=False)\n",
    "    (df.assign(abs_beta=lambda x: x[\"beta_dollars\"].abs())\n",
    "       .sort_values(\"abs_beta\", ascending=False)\n",
    "       .head(20)\n",
    "       .drop(columns=\"abs_beta\")\n",
    "       ).to_excel(xw, \"top_beta_contrib\", index=False)\n",
    "    (df.sort_values(\"mv_base\", key=lambda s: s.abs(), ascending=False)\n",
    "       .head(20)\n",
    "       ).to_excel(xw, \"top_exposures\", index=False)\n",
    "    df.sort_values(\"pct_adv\", ascending=False).to_excel(xw, \"liquidity\", index=False)\n",
    "    df.to_excel(xw, \"positions_enriched\", index=False)\n",
    "\n",
    "print(\"Wrote:\", out_txt, \"and\", out_xlsx)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-15T21:25:02.501559Z",
     "start_time": "2025-09-15T21:25:02.465877Z"
    }
   },
   "id": "cead3e09ad1abdae"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Factor-neutral global equities daily report\n",
    "-------------------------------------------\n",
    "Reads a positions CSV and produces:\n",
    "  - report.txt (plaintext pre-open summary)\n",
    "  - report_tables.xlsx (drill-down tabs)\n",
    "\n",
    "Assumptions:\n",
    "- CSV columns (case/space-insensitive, flexible names):\n",
    "  stock_id, name, ticker, country, currency, sector, beta,\n",
    "  avg_daily_volume, side, posn_shares, cost_basis_local, market_price_local\n",
    "- ADV is in shares/day. If it's in notional, switch %ADV formula accordingly.\n",
    "- FX to base is provided via --fx optional CSV (columns: currency,to_base).\n",
    "  If omitted, FX=1.0 and we clearly label that in the report.\n",
    "\n",
    "Usage:\n",
    "  python build_report.py --positions positions.csv --base USD --fx fx_latest.csv\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ----------------------------- Configuration ----------------------------- #\n",
    "\n",
    "@dataclass\n",
    "class Thresholds:\n",
    "    beta_drift: float = 0.015       # 1.5% of gross\n",
    "    currency_skew: float = 0.03     # 3% of gross\n",
    "    bucket_skew: float = 0.05       # 5% (country/sector)\n",
    "    single_name: float = 0.03       # 3% of gross\n",
    "    pct_adv_flag: float = 0.10      # 10% of ADV\n",
    "    liq_adjust_tau: float = 0.10    # 10% for liquidity-adjusted gross\n",
    "\n",
    "\n",
    "# ----------------------------- Utilities -------------------------------- #\n",
    "\n",
    "def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Standardize column names to snake_case lowercase for robust mapping.\"\"\"\n",
    "    out = df.copy()\n",
    "    out.columns = (\n",
    "        out.columns\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(r\"[\\s\\-]+\", \"_\", regex=True)\n",
    "    )\n",
    "    return out\n",
    "\n",
    "\n",
    "def pick(df: pd.DataFrame, choices: List[str], required: bool = True) -> Optional[str]:\n",
    "    \"\"\"Pick the first column present from a list of candidate names.\"\"\"\n",
    "    cols = set(df.columns)\n",
    "    for c in choices:\n",
    "        if c in cols:\n",
    "            return c\n",
    "    if required:\n",
    "        raise KeyError(f\"Missing required column; tried: {choices}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def load_fx_map(path: Optional[Path]) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Load FX rates if provided (CSV with columns ['currency','to_base']).\n",
    "    Return mapping {currency: to_base}. If path is None, return empty mapping.\n",
    "    \"\"\"\n",
    "    if path is None:\n",
    "        return {}\n",
    "    fx = pd.read_csv(path)\n",
    "    fx = normalize_columns(fx)\n",
    "    if not {\"currency\", \"to_base\"}.issubset(fx.columns):\n",
    "        raise ValueError(\"FX file must have columns: currency,to_base\")\n",
    "    return dict(zip(fx[\"currency\"], fx[\"to_base\"]))\n",
    "\n",
    "\n",
    "# ----------------------------- Core pipeline ----------------------------- #\n",
    "\n",
    "def load_positions(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load and minimally validate positions CSV; map canonical column names.\"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    df = normalize_columns(df)\n",
    "\n",
    "    # Map flexible input names to canonical ones\n",
    "    mapping = {\n",
    "        \"ticker\": pick(df, [\"ticker\", \"symbol\", \"ric\", \"bbg_ticker\", \"bbg\", \"sedol\", \"isin\"], required=False),\n",
    "        \"name\": pick(df, [\"name\", \"security_name\"], required=False),\n",
    "        \"stock_id\": pick(df, [\"stock_id\", \"id\"], required=False),\n",
    "        \"country\": pick(df, [\"country\", \"country_code\", \"iso_country\"], required=False),\n",
    "        \"currency\": pick(df, [\"currency\", \"ccy\", \"curr\"], required=True),\n",
    "        \"sector\": pick(df, [\"sector\", \"gics_sector\", \"industry_group\"], required=False),\n",
    "        \"industry\": pick(df, [\"industry\"], required=False),\n",
    "        \"sub_industry\": pick(df, [\"sub_industry\", \"subindustry\"], required=False),\n",
    "        \"beta\": pick(df, [\"beta\", \"capm_beta\", \"beta_to_index\"], required=True),\n",
    "        \"adv\": pick(df, [\"avg_daily_volume\", \"average_daily_volume\", \"adv\", \"adv_shares\"], required=True),\n",
    "        \"side\": pick(df, [\"side\", \"direction\"], required=False),\n",
    "        \"shares\": pick(df, [\"posn_shares\", \"position_shares\", \"shares\"], required=True),\n",
    "        \"cost\": pick(df, [\"cost_basis_local\", \"cost_basis\", \"avg_cost\"], required=False),\n",
    "        \"price\": pick(df, [\"market_price_local\", \"last_price\", \"px_last\", \"close\"], required=True),\n",
    "    }\n",
    "\n",
    "    # Rename present columns\n",
    "    ren = {v: k for k, v in mapping.items() if v is not None}\n",
    "    df = df.rename(columns=ren)\n",
    "\n",
    "    # Coerce numerics\n",
    "    for num in [\"beta\", \"adv\", \"shares\", \"cost\", \"price\"]:\n",
    "        if num in df.columns:\n",
    "            df[num] = pd.to_numeric(df[num], errors=\"coerce\")\n",
    "\n",
    "    # Fill missing optional classifiers for grouping\n",
    "    for opt in [\"ticker\", \"name\", \"stock_id\", \"country\", \"sector\", \"industry\", \"sub_industry\", \"side\"]:\n",
    "        if opt not in df.columns:\n",
    "            df[opt] = \"Unknown\"\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def enrich_positions(df: pd.DataFrame, fx_map: Dict[str, float]) -> pd.DataFrame:\n",
    "    \"\"\"Compute all derived fields used by analytics.\"\"\"\n",
    "    d = df.copy()\n",
    "\n",
    "    # FX to base; default to 1.0 if missing currency in map\n",
    "    d[\"fx_to_base\"] = d[\"currency\"].map(fx_map).fillna(1.0)\n",
    "\n",
    "    # Local notional and Mark-to-Base (MV_base)\n",
    "    d[\"notional_local\"] = d[\"shares\"] * d[\"price\"]\n",
    "    d[\"mv_base\"] = d[\"notional_local\"] * d[\"fx_to_base\"]\n",
    "\n",
    "    # Beta dollars (money-weighted beta exposure)\n",
    "    d[\"beta_dollars\"] = d[\"beta\"] * d[\"mv_base\"]\n",
    "\n",
    "    # Liquidity: %ADV (shares)\n",
    "    d[\"pct_adv\"] = np.where(d[\"adv\"] > 0, np.abs(d[\"shares\"]) / d[\"adv\"], np.nan)\n",
    "\n",
    "    # Unrealized P&L (absolute and %); cost may be absent or partially missing\n",
    "    if \"cost\" in d.columns and d[\"cost\"].notna().any():\n",
    "        d[\"unrl_pnl\"] = (d[\"price\"] - d[\"cost\"]) * d[\"shares\"]\n",
    "        d[\"unrl_pnl_pct\"] = np.where(d[\"cost\"] != 0, d[\"price\"] / d[\"cost\"] - 1.0, np.nan)\n",
    "    else:\n",
    "        d[\"unrl_pnl\"] = np.nan\n",
    "        d[\"unrl_pnl_pct\"] = np.nan\n",
    "\n",
    "    # Helpful: absolute MV and gross weight placeholder (fill after totals)\n",
    "    d[\"abs_mv_base\"] = d[\"mv_base\"].abs()\n",
    "\n",
    "    return d\n",
    "\n",
    "\n",
    "def portfolio_kpis(d: pd.DataFrame) -> Dict[str, float]:\n",
    "    \"\"\"Compute portfolio-level key performance indicators.\"\"\"\n",
    "    gross = float(d[\"abs_mv_base\"].sum())\n",
    "    net = float(d[\"mv_base\"].sum())\n",
    "    long_gross = float(d.loc[d[\"mv_base\"] > 0, \"mv_base\"].sum())\n",
    "    short_gross = float(d.loc[d[\"mv_base\"] < 0, \"mv_base\"].abs().sum())\n",
    "    long_pct = long_gross / gross if gross else 0.0\n",
    "    short_pct = short_gross / gross if gross else 0.0\n",
    "    net_beta = float(d[\"beta_dollars\"].sum())\n",
    "    beta_drift = abs(net_beta) / gross if gross else 0.0\n",
    "\n",
    "    # Liquidity share of gross in %ADV > 10%\n",
    "    liq_gross_share = float(d.loc[d[\"pct_adv\"] > 0.10, \"abs_mv_base\"].sum()) / (gross or 1.0)\n",
    "\n",
    "    # Top-10 concentration\n",
    "    top10_weight = float(d[\"abs_mv_base\"].nlargest(10).sum()) / (gross or 1.0)\n",
    "\n",
    "    return dict(\n",
    "        gross=gross, net=net,\n",
    "        long_pct=long_pct, short_pct=short_pct,\n",
    "        net_beta=net_beta, beta_drift=beta_drift,\n",
    "        liq_gross_10pct=liq_gross_share,\n",
    "        top10_weight=top10_weight\n",
    "    )\n",
    "\n",
    "\n",
    "def group_summary(d: pd.DataFrame, by: str) -> pd.DataFrame:\n",
    "    \"\"\"Aggregate Net, Gross, %Gross, Beta$, #names by a grouping dimension.\"\"\"\n",
    "    total_gross = d[\"abs_mv_base\"].sum() or 1.0\n",
    "    g = (\n",
    "        d.groupby(by, dropna=False)\n",
    "        .agg(\n",
    "            net=(\"mv_base\", \"sum\"),\n",
    "            gross=(\"abs_mv_base\", \"sum\"),\n",
    "            beta_dollars=(\"beta_dollars\", \"sum\"),\n",
    "            names=(\"ticker\", \"nunique\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    g[\"pct_gross\"] = g[\"gross\"] / total_gross\n",
    "    g = g.sort_values(\"pct_gross\", ascending=False)\n",
    "    return g\n",
    "\n",
    "\n",
    "def beta_buckets(d: pd.DataFrame, edges: List[float] = [-9, -0.5, 0, 0.5, 9]) -> pd.DataFrame:\n",
    "    \"\"\"Distribution of gross exposure across beta buckets.\"\"\"\n",
    "    # Bin betas; edges wide at ends to catch extremes\n",
    "    labels = [f\"[{edges[i]},{edges[i+1]})\" for i in range(len(edges)-1)]\n",
    "    b = d.copy()\n",
    "    b[\"beta_bin\"] = pd.cut(b[\"beta\"], bins=edges, labels=labels, include_lowest=True)\n",
    "    g = b.groupby(\"beta_bin\", dropna=False).agg(\n",
    "        gross=(\"abs_mv_base\", \"sum\"),\n",
    "        names=(\"ticker\", \"nunique\")\n",
    "    ).reset_index()\n",
    "    total_gross = d[\"abs_mv_base\"].sum() or 1.0\n",
    "    g[\"pct_gross\"] = g[\"gross\"] / total_gross\n",
    "    return g.sort_values(\"pct_gross\", ascending=False)\n",
    "\n",
    "\n",
    "def concentration_metrics(d: pd.DataFrame) -> Dict[str, float]:\n",
    "    \"\"\"Compute HHI concentration on absolute-MV weights.\"\"\"\n",
    "    gross = d[\"abs_mv_base\"].sum() or 1.0\n",
    "    w = d[\"abs_mv_base\"] / gross\n",
    "    hhi = float((w ** 2).sum())          # Herfindahl-Hirschman Index\n",
    "    return dict(hhi=hhi)\n",
    "\n",
    "\n",
    "def liquidity_adjusted_gross(d: pd.DataFrame, tau: float = 0.10) -> float:\n",
    "    \"\"\"\n",
    "    Liquidity-adjusted gross: down-weight gross by %ADV/tau (cap at 1).\n",
    "    Interprets tau=10% as 'full weight if %ADV >=10%, else proportional'.\n",
    "    \"\"\"\n",
    "    scale = np.minimum(1.0, (d[\"pct_adv\"] / tau).fillna(0.0))\n",
    "    lag = float((d[\"abs_mv_base\"] * scale).sum())\n",
    "    return lag\n",
    "\n",
    "\n",
    "def flags_and_watchlist(\n",
    "    d: pd.DataFrame,\n",
    "    kpis: Dict[str, float],\n",
    "    g_ccy: pd.DataFrame,\n",
    "    g_ctry: pd.DataFrame,\n",
    "    g_sect: pd.DataFrame,\n",
    "    thr: Thresholds,\n",
    ") -> List[str]:\n",
    "    \"\"\"Generate textual flags based on thresholds.\"\"\"\n",
    "    out = []\n",
    "    gross = kpis[\"gross\"] or 1.0\n",
    "\n",
    "    # Beta drift\n",
    "    if kpis[\"beta_drift\"] > thr.beta_drift:\n",
    "        out.append(f\"Market beta drift {kpis['beta_drift']:.2%} exceeds {thr.beta_drift:.2%} of gross\")\n",
    "\n",
    "    # Currency/Country/Sector skews\n",
    "    for label, g, lim in [(\"Currency\", g_ccy, thr.currency_skew),\n",
    "                          (\"Country\", g_ctry, thr.bucket_skew),\n",
    "                          (\"Sector\", g_sect, thr.bucket_skew)]:\n",
    "        sk = g.loc[g[\"net\"].abs() > lim * gross]\n",
    "        for _, r in sk.iterrows():\n",
    "            out.append(f\"{label} skew: {r[ label.lower() ]} net={r['net']:.0f} ({r['net']/gross:.2%} of gross)\")\n",
    "\n",
    "    # Single-name concentration\n",
    "    name_weights = d.assign(w=d[\"abs_mv_base\"] / gross).query(\"w > @thr.single_name\")\n",
    "    for _, r in name_weights.iterrows():\n",
    "        out.append(f\"Single-name concentration: {r.get('ticker','<NA>')} at {r['w']:.2%} of gross\")\n",
    "\n",
    "    # Liquidity\n",
    "    for _, r in d.loc[d[\"pct_adv\"] > thr.pct_adv_flag].iterrows():\n",
    "        out.append(f\"Liquidity: {r.get('ticker','<NA>')} at {r['pct_adv']:.1%} of ADV\")\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def qa_checks(d: pd.DataFrame) -> List[str]:\n",
    "    \"\"\"Data quality checks; return list of warnings (empty if all good).\"\"\"\n",
    "    warnings = []\n",
    "\n",
    "    # Missing values in critical fields\n",
    "    for col in [\"beta\", \"adv\", \"price\", \"shares\", \"currency\"]:\n",
    "        if d[col].isna().any():\n",
    "            n = int(d[col].isna().sum())\n",
    "            warnings.append(f\"{n} rows have missing '{col}'\")\n",
    "\n",
    "    # Non-positive ADV\n",
    "    bad_adv = (d[\"adv\"] <= 0) | d[\"adv\"].isna()\n",
    "    if bad_adv.any():\n",
    "        warnings.append(f\"{int(bad_adv.sum())} rows have non-positive or missing ADV (pct_adv set to NaN)\")\n",
    "\n",
    "    # Extreme betas\n",
    "    extreme_beta = (d[\"beta\"].abs() > 3).sum()\n",
    "    if extreme_beta:\n",
    "        warnings.append(f\"{int(extreme_beta)} rows have |beta| > 3 (clip or review)\")\n",
    "\n",
    "    # Reconciliation of MV sums (here identity by construction; keep as note)\n",
    "    # Additional checks can verify cost basis coherence, etc.\n",
    "\n",
    "    return warnings\n",
    "\n",
    "\n",
    "# ----------------------------- Output writers ---------------------------- #\n",
    "\n",
    "def fmt_money(x: float) -> str:\n",
    "    try:\n",
    "        return f\"{x:,.0f}\"\n",
    "    except Exception:\n",
    "        return str(x)\n",
    "\n",
    "\n",
    "def write_text_report(\n",
    "    out_path: Path,\n",
    "    base_ccy: str,\n",
    "    used_real_fx: bool,\n",
    "    d: pd.DataFrame,\n",
    "    kpis: Dict[str, float],\n",
    "    g_ccy: pd.DataFrame,\n",
    "    g_ctry: pd.DataFrame,\n",
    "    g_sect: pd.DataFrame,\n",
    "    beta_bins: pd.DataFrame,\n",
    "    lag: float,\n",
    "    hhi: float,\n",
    "    flags: List[str],\n",
    "    qa: List[str],\n",
    ") -> None:\n",
    "    \"\"\"Compose and write the plaintext pre-open report.\"\"\"\n",
    "    lines: List[str] = []\n",
    "    fx_note = \"real FX applied\" if used_real_fx else \"FX=1.0 placeholder (approximate cross-currency totals)\"\n",
    "\n",
    "    lines.append(f\"FACTOR-NEUTRAL EQUITIES REPORT | Base: {base_ccy} | {fx_note}\")\n",
    "    lines.append(f\"Rows: {len(d)}\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    # KPIs\n",
    "    lines.append(\"Portfolio KPIs\")\n",
    "    lines.append(f\"  Gross: {fmt_money(kpis['gross'])} | Net: {fmt_money(kpis['net'])} | \"\n",
    "                 f\"Long%: {kpis['long_pct']:.1%} | Short%: {kpis['short_pct']:.1%}\")\n",
    "    lines.append(f\"  Net beta-$: {fmt_money(kpis['net_beta'])} | Beta drift: {kpis['beta_drift']:.2%} of gross\")\n",
    "    lines.append(f\"  Liquidity (>%ADV 10%): {kpis['liq_gross_10pct']:.1%} of gross | \"\n",
    "                 f\"Top-10 names: {kpis['top10_weight']:.1%} of gross\")\n",
    "    lines.append(f\"  Liquidity-adjusted gross (LAG): {fmt_money(lag)} | HHI: {hhi:.4f}\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    # Buckets (top)\n",
    "    def block(title: str, g: pd.DataFrame, show: int = 8) -> List[str]:\n",
    "        t = g.copy().head(show)\n",
    "        t[\"net\"] = t[\"net\"].map(fmt_money)\n",
    "        t[\"gross\"] = t[\"gross\"].map(fmt_money)\n",
    "        t[\"beta_dollars\"] = t[\"beta_dollars\"].map(fmt_money)\n",
    "        t[\"pct_gross\"] = (t[\"pct_gross\"] * 100).map(lambda v: f\"{v:.1f}%\")\n",
    "        return [title, t.to_string(index=False), \"\"]\n",
    "\n",
    "    lines += block(\"Top Currency Buckets (by % gross)\", g_ccy)\n",
    "    lines += block(\"Top Country Buckets (by % gross)\", g_ctry)\n",
    "    lines += block(\"Top Sector Buckets (by % gross)\", g_sect)\n",
    "\n",
    "    # Beta buckets\n",
    "    t = beta_bins.copy()\n",
    "    t[\"gross\"] = t[\"gross\"].map(fmt_money)\n",
    "    t[\"pct_gross\"] = (t[\"pct_gross\"] * 100).map(lambda v: f\"{v:.1f}%\")\n",
    "    lines.append(\"Beta Buckets (gross distribution)\")\n",
    "    lines.append(t.to_string(index=False))\n",
    "    lines.append(\"\")\n",
    "\n",
    "    # Watchlist flags\n",
    "    lines.append(\"Watchlist Flags\")\n",
    "    if flags:\n",
    "        lines += [f\"  - {f}\" for f in flags]\n",
    "    else:\n",
    "        lines.append(\"  (None)\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    # QA warnings\n",
    "    if qa:\n",
    "        lines.append(\"Data Quality Notes\")\n",
    "        lines += [f\"  - {w}\" for w in qa]\n",
    "        lines.append(\"\")\n",
    "\n",
    "    out_path.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "def write_excel_report(\n",
    "    out_xlsx: Path,\n",
    "    d: pd.DataFrame,\n",
    "    g_ccy: pd.DataFrame,\n",
    "    g_ctry: pd.DataFrame,\n",
    "    g_sect: pd.DataFrame,\n",
    "    beta_bins: pd.DataFrame,\n",
    ") -> None:\n",
    "    \"\"\"Write drill-down workbook with pivots and enriched positions.\"\"\"\n",
    "    with pd.ExcelWriter(out_xlsx, engine=\"xlsxwriter\") as xw:\n",
    "        g_ccy.to_excel(xw, sheet_name=\"by_currency\", index=False)\n",
    "        g_ctry.to_excel(xw, sheet_name=\"by_country\", index=False)\n",
    "        g_sect.to_excel(xw, sheet_name=\"by_sector\", index=False)\n",
    "\n",
    "        # Top beta contributors (absolute)\n",
    "        (d.assign(abs_beta=lambda x: x[\"beta_dollars\"].abs())\n",
    "           .sort_values(\"abs_beta\", ascending=False)\n",
    "           .drop(columns=[\"abs_beta\"])\n",
    "           .head(50)\n",
    "           ).to_excel(xw, sheet_name=\"top_beta_contrib\", index=False)\n",
    "\n",
    "        # Top exposures by absolute MV\n",
    "        (d.sort_values(\"abs_mv_base\", ascending=False)\n",
    "           .head(50)\n",
    "           ).to_excel(xw, sheet_name=\"top_exposures\", index=False)\n",
    "\n",
    "        # Liquidity detail sorted by %ADV\n",
    "        (d.sort_values(\"pct_adv\", ascending=False)\n",
    "           ).to_excel(xw, sheet_name=\"liquidity\", index=False)\n",
    "\n",
    "        # Beta bucket distribution\n",
    "        beta_bins.to_excel(xw, sheet_name=\"beta_buckets\", index=False)\n",
    "\n",
    "        # Raw enriched positions\n",
    "        d.to_excel(xw, sheet_name=\"positions_enriched\", index=False)\n",
    "\n",
    "\n",
    "# ----------------------------- Main CLI --------------------------------- #\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser(description=\"Build factor-neutral equities daily report.\")\n",
    "    ap.add_argument(\"--positions\", type=Path, required=True, help=\"Path to positions CSV\")\n",
    "    ap.add_argument(\"--fx\", type=Path, default=None, help=\"Optional FX CSV (currency,to_base)\")\n",
    "    ap.add_argument(\"--base\", type=str, default=\"USD\", help=\"Base currency label for report header\")\n",
    "    ap.add_argument(\"--out_txt\", type=Path, default=Path(\"report.txt\"), help=\"Output plaintext report\")\n",
    "    ap.add_argument(\"--out_xlsx\", type=Path, default=Path(\"report_tables.xlsx\"), help=\"Output Excel workbook\")\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    # Load data and FX\n",
    "    fx_map = load_fx_map(args.fx)\n",
    "    df = load_positions(args.positions)\n",
    "\n",
    "    # Enrich with derived fields\n",
    "    d = enrich_positions(df, fx_map)\n",
    "\n",
    "    # KPIs\n",
    "    kpis = portfolio_kpis(d)\n",
    "\n",
    "    # Group summaries\n",
    "    g_ccy = group_summary(d, \"currency\")\n",
    "    g_ctry = group_summary(d, \"country\")\n",
    "    g_sect = group_summary(d, \"sector\")\n",
    "\n",
    "    # Beta bucket distribution\n",
    "    beta_bins = beta_buckets(d)\n",
    "\n",
    "    # Concentration metrics (HHI) and Liquidity-adjusted gross\n",
    "    conc = concentration_metrics(d)\n",
    "    lag = liquidity_adjusted_gross(d, tau=Thresholds().liq_adjust_tau)\n",
    "\n",
    "    # Flags and QA\n",
    "    thr = Thresholds()\n",
    "    flags = flags_and_watchlist(d, kpis, g_ccy, g_ctry, g_sect, thr)\n",
    "    qa = qa_checks(d)\n",
    "\n",
    "    # Write outputs\n",
    "    used_real_fx = any(val != 1.0 for val in d[\"fx_to_base\"].unique())\n",
    "    write_text_report(\n",
    "        out_path=args.out_txt,\n",
    "        base_ccy=args.base,\n",
    "        used_real_fx=used_real_fx,\n",
    "        d=d, kpis=kpis,\n",
    "        g_ccy=g_ccy, g_ctry=g_ctry, g_sect=g_sect,\n",
    "        beta_bins=beta_bins,\n",
    "        lag=lag, hhi=conc[\"hhi\"],\n",
    "        flags=flags, qa=qa\n",
    "    )\n",
    "    write_excel_report(args.out_xlsx, d, g_ccy, g_ctry, g_sect, beta_bins)\n",
    "\n",
    "    print(f\"Wrote {args.out_txt} and {args.out_xlsx}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c11a47753de6f1fd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "currency,to_base\n",
    "EUR,1.08\n",
    "GBP,1.30\n",
    "JPY,0.0063\n",
    "...\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a080ebbf4f9451f1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "All-in-one daily report (compact version)\n",
    "-----------------------------------------\n",
    "Reads positions.csv and outputs:\n",
    "  - report.txt (plaintext summary)\n",
    "  - report_tables.xlsx (drill-downs)\n",
    "\n",
    "Assumes:\n",
    "- CSV has columns (case-insensitive, flexible names):\n",
    "  stock_id, name, ticker, country, currency, sector, industry, sub_industry,\n",
    "  beta, avg_daily_volume, side, posn_shares, cost_basis_local, market_price_local\n",
    "- ADV is in shares/day. If in notional, change %ADV formula accordingly.\n",
    "- FX to base: populate FX_TO_BASE below (or leave blank => 1.0 everywhere).\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# ---------------- USER KNOBS ---------------- #\n",
    "INPUT_CSV   = \"positions.csv\"\n",
    "OUT_TXT     = \"report.txt\"\n",
    "OUT_XLSX    = \"report_tables.xlsx\"\n",
    "BASE_CCY    = \"USD\"  # label only\n",
    "\n",
    "# Optional FX map (local -> base). Leave {} to use 1.0 everywhere.\n",
    "FX_TO_BASE = {\n",
    "    # \"EUR\": 1.08, \"GBP\": 1.30, \"JPY\": 0.0063, \"AUD\": 0.66, \"CHF\": 1.12,\n",
    "    # \"CAD\": 0.73, \"CNY\": 0.14, \"HKD\": 0.13, \"BRL\": 0.18, ...\n",
    "}\n",
    "\n",
    "# Thresholds for flags\n",
    "THR = dict(\n",
    "    beta_drift=0.015,     # 1.5% of gross\n",
    "    ccy_skew=0.03,        # currency |Net|/Gross > 3%\n",
    "    bucket_skew=0.05,     # country/sector |Net|/Gross > 5%\n",
    "    single_name=0.03,     # name |MV|/Gross > 3%\n",
    "    pctadv=0.10,          # %ADV > 10%\n",
    "    liq_tau=0.10          # liquidity-adjusted gross threshold (10%)\n",
    ")\n",
    "\n",
    "# Beta bucket edges for distribution view\n",
    "BETA_BUCKETS = [-9, -0.5, 0, 0.5, 9]\n",
    "# ------------------------------------------- #\n",
    "\n",
    "\n",
    "# ---------- Helpers ---------- #\n",
    "def std_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Normalize columns: lower snake_case.\"\"\"\n",
    "    out = df.copy()\n",
    "    out.columns = (out.columns.str.strip().str.lower()\n",
    "                   .str.replace(r\"[\\s\\-]+\", \"_\", regex=True))\n",
    "    return out\n",
    "\n",
    "def load_positions(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Read CSV, coerce core columns, and rename to canonical names.\"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    df = std_cols(df)\n",
    "    df = df.rename(columns={\n",
    "        \"avg_daily_volume\": \"adv\",\n",
    "        \"posn_shares\": \"shares\",\n",
    "        \"cost_basis_local\": \"cost\",\n",
    "        \"market_price_local\": \"price\",\n",
    "    })\n",
    "    # Numeric coercion (ignore if missing)\n",
    "    for c in [\"beta\", \"adv\", \"shares\", \"cost\", \"price\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    # Ensure grouping cols exist\n",
    "    for c in [\"currency\", \"country\", \"sector\", \"ticker\", \"name\", \"industry\", \"sub_industry\"]:\n",
    "        if c not in df.columns:\n",
    "            df[c] = \"Unknown\"\n",
    "    if \"side\" not in df.columns:\n",
    "        df[\"side\"] = np.where(df.get(\"shares\", 0) >= 0, \"LONG\", \"SHORT\")\n",
    "    return df\n",
    "\n",
    "def enrich(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Compute core derived fields used throughout the report.\"\"\"\n",
    "    d = df.copy()\n",
    "    d[\"fx_to_base\"] = d[\"currency\"].map(FX_TO_BASE).fillna(1.0)\n",
    "    d[\"notional_local\"] = d[\"shares\"] * d[\"price\"]\n",
    "    d[\"mv_base\"] = d[\"notional_local\"] * d[\"fx_to_base\"]\n",
    "    d[\"abs_mv_base\"] = d[\"mv_base\"].abs()\n",
    "    d[\"beta_dollars\"] = d[\"beta\"] * d[\"mv_base\"]\n",
    "    d[\"pct_adv\"] = np.where(d[\"adv\"] > 0, np.abs(d[\"shares\"]) / d[\"adv\"], np.nan)\n",
    "    # P&L (optional)\n",
    "    if \"cost\" in d.columns and d[\"cost\"].notna().any():\n",
    "        d[\"unrl_pnl\"] = (d[\"price\"] - d[\"cost\"]) * d[\"shares\"]\n",
    "        d[\"unrl_pnl_pct\"] = np.where(d[\"cost\"] != 0, d[\"price\"]/d[\"cost\"] - 1.0, np.nan)\n",
    "    else:\n",
    "        d[\"unrl_pnl\"] = np.nan\n",
    "        d[\"unrl_pnl_pct\"] = np.nan\n",
    "    return d\n",
    "\n",
    "def kpis(d: pd.DataFrame) -> dict:\n",
    "    g = d[\"abs_mv_base\"].sum()\n",
    "    n = d[\"mv_base\"].sum()\n",
    "    long_g = d.loc[d[\"mv_base\"] > 0, \"mv_base\"].sum()\n",
    "    short_g = d.loc[d[\"mv_base\"] < 0, \"mv_base\"].abs().sum()\n",
    "    net_beta = d[\"beta_dollars\"].sum()\n",
    "    return dict(\n",
    "        gross=g,\n",
    "        net=n,\n",
    "        long_pct=(long_g/g) if g else 0.0,\n",
    "        short_pct=(short_g/g) if g else 0.0,\n",
    "        net_beta=net_beta,\n",
    "        beta_drift=(abs(net_beta)/g) if g else 0.0,\n",
    "        liq_gross_10pct=(d.loc[d[\"pct_adv\"] > THR[\"pctadv\"], \"abs_mv_base\"].sum()/(g or 1.0)),\n",
    "        top10_weight=(d[\"abs_mv_base\"].nlargest(10).sum()/(g or 1.0))\n",
    "    )\n",
    "\n",
    "def group_summary(d: pd.DataFrame, by: str) -> pd.DataFrame:\n",
    "    \"\"\"Net, Gross, %Gross, Beta$, #names for a dimension.\"\"\"\n",
    "    total_gross = d[\"abs_mv_base\"].sum() or 1.0\n",
    "    g = (d.groupby(by, dropna=False)\n",
    "          .agg(net=(\"mv_base\", \"sum\"),\n",
    "               gross=(\"abs_mv_base\", \"sum\"),\n",
    "               beta_dollars=(\"beta_dollars\", \"sum\"),\n",
    "               names=(\"ticker\", \"nunique\"))\n",
    "          .reset_index())\n",
    "    g[\"pct_gross\"] = g[\"gross\"] / total_gross\n",
    "    return g.sort_values(\"pct_gross\", ascending=False)\n",
    "\n",
    "def beta_bucket_dist(d: pd.DataFrame, edges=BETA_BUCKETS) -> pd.DataFrame:\n",
    "    labels = [f\"[{edges[i]},{edges[i+1]})\" for i in range(len(edges)-1)]\n",
    "    b = d.copy()\n",
    "    b[\"beta_bin\"] = pd.cut(b[\"beta\"], bins=edges, labels=labels, include_lowest=True)\n",
    "    g = b.groupby(\"beta_bin\", dropna=False).agg(\n",
    "        gross=(\"abs_mv_base\", \"sum\"),\n",
    "        names=(\"ticker\", \"nunique\")\n",
    "    ).reset_index()\n",
    "    total_gross = d[\"abs_mv_base\"].sum() or 1.0\n",
    "    g[\"pct_gross\"] = g[\"gross\"] / total_gross\n",
    "    return g.sort_values(\"pct_gross\", ascending=False)\n",
    "\n",
    "def concentration_hhi(d: pd.DataFrame) -> float:\n",
    "    g = d[\"abs_mv_base\"].sum() or 1.0\n",
    "    w = d[\"abs_mv_base\"] / g\n",
    "    return float((w**2).sum())\n",
    "\n",
    "def liquidity_adjusted_gross(d: pd.DataFrame, tau: float) -> float:\n",
    "    \"\"\"Down-weight exposures by min(1, %ADV/tau).\"\"\"\n",
    "    scale = np.minimum(1.0, (d[\"pct_adv\"]/tau).fillna(0.0))\n",
    "    return float((d[\"abs_mv_base\"] * scale).sum())\n",
    "\n",
    "def make_flags(d: pd.DataFrame, k: dict,\n",
    "               g_ccy: pd.DataFrame, g_ctry: pd.DataFrame, g_sect: pd.DataFrame) -> list:\n",
    "    flags = []\n",
    "    gross = k[\"gross\"] or 1.0\n",
    "\n",
    "    # Beta drift\n",
    "    if k[\"beta_drift\"] > THR[\"beta_drift\"]:\n",
    "        flags.append(f\"Market beta drift {k['beta_drift']:.2%} > {THR['beta_drift']:.2%}\")\n",
    "\n",
    "    # Group skews\n",
    "    for label, g, lim in [(\"Currency\", g_ccy, THR[\"ccy_skew\"]),\n",
    "                          (\"Country\", g_ctry, THR[\"bucket_skew\"]),\n",
    "                          (\"Sector\",  g_sect, THR[\"bucket_skew\"])]:\n",
    "        sk = g.loc[g[\"net\"].abs() > lim * gross]\n",
    "        for _, r in sk.iterrows():\n",
    "            flags.append(f\"{label} skew {r[label.lower()]}: net {r['net']:.0f} ({r['net']/gross:.2%} of gross)\")\n",
    "\n",
    "    # Single-name concentration\n",
    "    big = d.assign(w=d[\"abs_mv_base\"]/(gross or 1.0)).query(\"w > @THR['single_name']\")\n",
    "    for _, r in big.iterrows():\n",
    "        flags.append(f\"Single-name concentration {r.get('ticker','<NA>')}: {r['w']:.2%} of gross\")\n",
    "\n",
    "    # Liquidity\n",
    "    liq = d.loc[d[\"pct_adv\"] > THR[\"pctadv\"]]\n",
    "    for _, r in liq.iterrows():\n",
    "        flags.append(f\"Liquidity {r.get('ticker','<NA>')}: {r['pct_adv']:.1%} of ADV\")\n",
    "\n",
    "    return flags\n",
    "\n",
    "def qa_notes(d: pd.DataFrame) -> list:\n",
    "    notes = []\n",
    "    for col in [\"beta\", \"adv\", \"price\", \"shares\", \"currency\"]:\n",
    "        if d[col].isna().any():\n",
    "            notes.append(f\"{int(d[col].isna().sum())} rows missing '{col}'\")\n",
    "    bad_adv = (d[\"adv\"] <= 0) | d[\"adv\"].isna()\n",
    "    if bad_adv.any():\n",
    "        notes.append(f\"{int(bad_adv.sum())} rows have non-positive/missing ADV (pct_adv NaN)\")\n",
    "    extreme_beta = (d[\"beta\"].abs() > 3).sum()\n",
    "    if extreme_beta:\n",
    "        notes.append(f\"{int(extreme_beta)} rows have |beta|>3 (review)\")\n",
    "    return notes\n",
    "\n",
    "def fmt_money(x: float) -> str:\n",
    "    try: return f\"{x:,.0f}\"\n",
    "    except: return str(x)\n",
    "\n",
    "\n",
    "# ---------- Main ---------- #\n",
    "def main():\n",
    "    df = load_positions(INPUT_CSV)\n",
    "    d  = enrich(df)\n",
    "\n",
    "    # KPIs and analytics\n",
    "    K = kpis(d)\n",
    "    g_ccy  = group_summary(d, \"currency\")\n",
    "    g_ctry = group_summary(d, \"country\")\n",
    "    g_sect = group_summary(d, \"sector\")\n",
    "    beta_bins = beta_bucket_dist(d)\n",
    "    hhi = concentration_hhi(d)\n",
    "    lag = liquidity_adjusted_gross(d, tau=THR[\"liq_tau\"])\n",
    "    flags = make_flags(d, K, g_ccy, g_ctry, g_sect)\n",
    "    qa = qa_notes(d)\n",
    "\n",
    "    # ---- Write plaintext report ----\n",
    "    lines = []\n",
    "    fx_note = \"real FX applied\" if any(d[\"fx_to_base\"].unique() != 1.0) else \"FX=1.0 placeholder\"\n",
    "    lines.append(f\"FACTOR-NEUTRAL EQUITIES REPORT | {datetime.now():%Y-%m-%d %H:%M} | Base: {BASE_CCY} | {fx_note}\")\n",
    "    lines.append(f\"Rows: {len(d)}\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"Portfolio KPIs\")\n",
    "    lines.append(f\"  Gross: {fmt_money(K['gross'])} | Net: {fmt_money(K['net'])} | \"\n",
    "                 f\"Long%: {K['long_pct']:.1%} | Short%: {K['short_pct']:.1%}\")\n",
    "    lines.append(f\"  Net beta-$: {fmt_money(K['net_beta'])} | Beta drift: {K['beta_drift']:.2%} of gross\")\n",
    "    lines.append(f\"  Liquidity (>%ADV 10%): {K['liq_gross_10pct']:.1%} of gross | \"\n",
    "                 f\"Top-10 names: {K['top10_weight']:.1%} of gross\")\n",
    "    lines.append(f\"  Liquidity-adjusted gross (LAG): {fmt_money(lag)} | HHI: {hhi:.4f}\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    def add_block(title, g, show=10):\n",
    "        t = g.copy().head(show)\n",
    "        t[\"net\"] = t[\"net\"].map(fmt_money)\n",
    "        t[\"gross\"] = t[\"gross\"].map(fmt_money)\n",
    "        t[\"beta_dollars\"] = t[\"beta_dollars\"].map(fmt_money)\n",
    "        t[\"pct_gross\"] = (t[\"pct_gross\"]*100).map(lambda v: f\"{v:.1f}%\")\n",
    "        lines.append(title)\n",
    "        lines.append(t.to_string(index=False))\n",
    "        lines.append(\"\")\n",
    "\n",
    "    add_block(\"Top Currency Buckets (by % gross)\", g_ccy)\n",
    "    add_block(\"Top Country Buckets (by % gross)\",  g_ctry)\n",
    "    add_block(\"Top Sector Buckets (by % gross)\",   g_sect)\n",
    "\n",
    "    # Beta buckets\n",
    "    tb = beta_bins.copy()\n",
    "    tb[\"gross\"] = tb[\"gross\"].map(fmt_money)\n",
    "    tb[\"pct_gross\"] = (tb[\"pct_gross\"]*100).map(lambda v: f\"{v:.1f}%\")\n",
    "    lines.append(\"Beta Buckets (gross distribution)\")\n",
    "    lines.append(tb.to_string(index=False))\n",
    "    lines.append(\"\")\n",
    "\n",
    "    # Optional quick stress/hedge prompts (numbers are already above)\n",
    "    lines.append(\"Stress/Hedge Quick Numbers\")\n",
    "    lines.append(\"  Market stress: Î”PnL â‰ˆ (index move %) Ã— Net Beta-$ / 100\")\n",
    "    lines.append(\"  Beta hedge notional (if Î²_indexâ‰ˆ1): trade â‰ˆ - Net Beta-$\")\n",
    "    lines.append(\"  FX stress by currency c: Î”PnL_c â‰ˆ (FX move %) Ã— Net(c) / 100\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    # Flags\n",
    "    lines.append(\"Watchlist Flags\")\n",
    "    if flags:\n",
    "        for f in flags: lines.append(f\"  - {f}\")\n",
    "    else:\n",
    "        lines.append(\"  (None)\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    # QA\n",
    "    if qa:\n",
    "        lines.append(\"Data Quality Notes\")\n",
    "        for q in qa: lines.append(f\"  - {q}\")\n",
    "        lines.append(\"\")\n",
    "\n",
    "    Path(OUT_TXT).write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "    print(f\"Wrote {OUT_TXT}\")\n",
    "\n",
    "    # ---- Write Excel workbook ----\n",
    "    with pd.ExcelWriter(OUT_XLSX, engine=\"xlsxwriter\") as xw:\n",
    "        g_ccy.to_excel(xw, \"by_currency\", index=False)\n",
    "        g_ctry.to_excel(xw, \"by_country\", index=False)\n",
    "        g_sect.to_excel(xw, \"by_sector\", index=False)\n",
    "\n",
    "        (d.assign(abs_beta=lambda x: x[\"beta_dollars\"].abs())\n",
    "           .sort_values(\"abs_beta\", ascending=False)\n",
    "           .drop(columns=[\"abs_beta\"])\n",
    "           .head(50)\n",
    "           ).to_excel(xw, \"top_beta_contrib\", index=False)\n",
    "\n",
    "        (d.sort_values(\"abs_mv_base\", ascending=False)\n",
    "           .head(50)\n",
    "           ).to_excel(xw, \"top_exposures\", index=False)\n",
    "\n",
    "        d.sort_values(\"pct_adv\", ascending=False).to_excel(xw, \"liquidity\", index=False)\n",
    "        beta_bins.to_excel(xw, \"beta_buckets\", index=False)\n",
    "        d.to_excel(xw, \"positions_enriched\", index=False)\n",
    "\n",
    "    print(f\"Wrote {OUT_XLSX}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "376f2315d875760b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
